{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10970045,"sourceType":"datasetVersion","datasetId":6825755}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport re\nfrom tqdm.auto import tqdm\nfrom collections import Counter\nimport os\n\n# 2. Setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# 3. Load Data\ntrain_file = \"/kaggle/input/c-ours/C_Ours/data_C_Ours_train.csv\"\ntest_file = \"/kaggle/input/c-ours/C_Ours/data_C_Ours_test.csv\"\n\ntrain_df = pd.read_csv(train_file)\ntest_df = pd.read_csv(test_file)\n\n# 4. Clean Code\ndef clean_code(code):\n    code = re.sub(r'//.*?(\\n|$)', ' ', code)  # Single-line comments\n    code = re.sub(r'/\\*.*?\\*/', ' ', code, flags=re.DOTALL)  # Multi-line comments\n    code = re.sub(r'\\s+', ' ', code.strip())  # Normalize whitespace\n    return code\n\ntrain_df['code'] = train_df['code'].apply(clean_code)\ntest_df['code'] = test_df['code'].apply(clean_code)\n\n# 5. Split data for validation\ntrain_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df['target'])\n\n# 6. Character-level tokenizer for LSTM\ndef build_vocab(codes):\n    vocab = set()\n    for code in codes:\n        vocab.update(list(code))\n    vocab = sorted(list(vocab))\n    vocab_dict = {char: idx+1 for idx, char in enumerate(vocab)}  # 0 is reserved for padding\n    vocab_dict['<PAD>'] = 0\n    return vocab_dict\n\nvocab = build_vocab(train_df['code'])\n\ndef encode_code(code, vocab, max_len=512):\n    encoded = [vocab.get(c, 0) for c in code]\n    if len(encoded) > max_len:\n        encoded = encoded[:max_len]\n    else:\n        encoded += [0] * (max_len - len(encoded))\n    return encoded\n\n# 7. Word-level tokenizer for transformer approach\ndef get_word_vocab(codes, max_size=10000):\n    \"\"\"Build a word-level vocabulary from code samples\"\"\"\n    # Tokenize code into words (considering code tokens)\n    all_words = []\n    for code in codes:\n        # Simple tokenization: split by spaces and separate symbols\n        tokens = re.findall(r'\\w+|[^\\w\\s]', code)\n        all_words.extend(tokens)\n    \n    # Count word frequencies\n    word_counts = Counter(all_words)\n    \n    # Create vocabulary dict with most common words\n    common_words = word_counts.most_common(max_size-4)  # Leave room for special tokens\n    word_vocab = {\n        '<PAD>': 0,\n        '<UNK>': 1,\n        '<SOS>': 2,\n        '<EOS>': 3,\n    }\n    for i, (word, _) in enumerate(common_words):\n        word_vocab[word] = i + 4\n    \n    return word_vocab\n\ndef tokenize_code(code, word_vocab, max_len=256):\n    \"\"\"Tokenize code into words and convert to indices\"\"\"\n    tokens = re.findall(r'\\w+|[^\\w\\s]', code)\n    # Convert tokens to indices\n    indices = [word_vocab.get(token, word_vocab['<UNK>']) for token in tokens]\n    # Truncate or pad to max_len\n    if len(indices) > max_len - 2:  # Account for SOS and EOS\n        indices = indices[:max_len-2]\n    \n    # Add SOS and EOS tokens\n    indices = [word_vocab['<SOS>']] + indices + [word_vocab['<EOS>']]\n    # Pad to max_len\n    padding_length = max_len - len(indices)\n    if padding_length > 0:\n        indices += [word_vocab['<PAD>']] * padding_length\n    \n    return indices\n\n# Create word vocabulary\nword_vocab = get_word_vocab(train_df['code'])\nprint(f\"Word vocabulary size: {len(word_vocab)}\")\n\n# 8. Dataset\nclass CodeDataset(Dataset):\n    def __init__(self, dataframe, char_vocab, word_vocab, max_char_len=512, max_word_len=256):\n        self.codes = dataframe['code'].tolist()\n        self.labels = dataframe['target'].tolist()\n        self.char_vocab = char_vocab\n        self.word_vocab = word_vocab\n        self.max_char_len = max_char_len\n        self.max_word_len = max_word_len\n\n    def __len__(self):\n        return len(self.codes)\n\n    def __getitem__(self, idx):\n        code = self.codes[idx]\n        label = self.labels[idx]\n        \n        # Character encoding for LSTM\n        char_encoded = encode_code(code, self.char_vocab, self.max_char_len)\n        \n        # Word encoding for transformer\n        word_encoded = tokenize_code(code, self.word_vocab, self.max_word_len)\n        \n        # Create attention mask (1 for tokens, 0 for padding)\n        attention_mask = [1 if token != self.word_vocab['<PAD>'] else 0 for token in word_encoded]\n        \n        return {\n            'char_encoded': torch.tensor(char_encoded, dtype=torch.long),\n            'word_encoded': torch.tensor(word_encoded, dtype=torch.long),\n            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n            'labels': torch.tensor(label, dtype=torch.float)\n        }\n\n# 9. Dataloaders\ntrain_dataset = CodeDataset(train_df, vocab, word_vocab)\nval_dataset = CodeDataset(val_df, vocab, word_vocab)\ntest_dataset = CodeDataset(test_df, vocab, word_vocab)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# 10. Transformer Encoder Layer\nclass TransformerEncoderLayer(nn.Module):\n    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n        super(TransformerEncoderLayer, self).__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n        \n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n        \n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n        \n        self.activation = nn.GELU()\n        \n    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n        # Self-attention block\n        src2, _ = self.self_attn(src, src, src, \n                                key_padding_mask=src_key_padding_mask,\n                                attn_mask=src_mask)\n        src = src + self.dropout1(src2)\n        src = self.norm1(src)\n        \n        # Feedforward block\n        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n        src = src + self.dropout2(src2)\n        src = self.norm2(src)\n        \n        return src\n\n# 11. Hybrid LSTM+Transformer Model\nclass HybridCodeClassifier(nn.Module):\n    def __init__(self, char_vocab_size, word_vocab_size, \n                 char_embedding_dim=64, word_embedding_dim=128,\n                 lstm_hidden_dim=128, transformer_dim=256, nhead=4, \n                 num_transformer_layers=2, dropout=0.3):\n        super(HybridCodeClassifier, self).__init__()\n        \n        # LSTM part\n        self.char_embedding = nn.Embedding(char_vocab_size, char_embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(char_embedding_dim, lstm_hidden_dim, num_layers=2, \n                           batch_first=True, dropout=dropout, bidirectional=True)\n        self.lstm_dropout = nn.Dropout(dropout)\n        \n        # Transformer part\n        self.word_embedding = nn.Embedding(word_vocab_size, word_embedding_dim, padding_idx=0)\n        self.pos_encoder = nn.Embedding(512, word_embedding_dim)  # Position encoding\n        self.input_proj = nn.Linear(word_embedding_dim, transformer_dim)\n        \n        # Transformer layers\n        self.transformer_layers = nn.ModuleList([\n            TransformerEncoderLayer(transformer_dim, nhead, dim_feedforward=transformer_dim*4, dropout=dropout)\n            for _ in range(num_transformer_layers)\n        ])\n        self.transformer_dropout = nn.Dropout(dropout)\n        \n        # For feature fusion\n        lstm_output_dim = lstm_hidden_dim * 2  # bidirectional\n        self.transformer_pooler = nn.Linear(transformer_dim, transformer_dim)\n        self.transformer_pooler_activation = nn.Tanh()\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(transformer_dim + lstm_output_dim, 256)\n        self.fc2 = nn.Linear(256, 1)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, char_input, word_input, attention_mask):\n        batch_size = char_input.size(0)\n        \n        # LSTM forward pass\n        char_embedded = self.char_embedding(char_input)\n        lstm_out, (hidden, _) = self.lstm(char_embedded)\n        # Concatenate the final forward and backward hidden states\n        lstm_feature = torch.cat((hidden[-2], hidden[-1]), dim=1)\n        lstm_feature = self.lstm_dropout(lstm_feature)\n        \n        # Transformer forward pass\n        word_embedded = self.word_embedding(word_input)\n        \n        # Add positional encoding\n        positions = torch.arange(0, word_input.size(1), device=device).unsqueeze(0).expand(batch_size, -1)\n        pos_encoded = self.pos_encoder(positions)\n        \n        # Combine word embeddings with position encodings\n        word_embedded = word_embedded + pos_encoded\n        \n        # Project to transformer dimension\n        transformer_input = self.input_proj(word_embedded)\n        \n        # Create padding mask (1 means padding position)\n        padding_mask = (attention_mask == 0)\n        \n        # Apply transformer layers\n        transformer_output = transformer_input\n        for layer in self.transformer_layers:\n            transformer_output = layer(transformer_output, src_key_padding_mask=padding_mask)\n        \n        # Pool transformer output (use [CLS] token or average)\n        # Using first token as [CLS] equivalent\n        transformer_pooled = self.transformer_pooler_activation(\n            self.transformer_pooler(transformer_output[:, 0])\n        )\n        transformer_feature = self.transformer_dropout(transformer_pooled)\n        \n        # Concatenate features from both models\n        combined_features = torch.cat((lstm_feature, transformer_feature), dim=1)\n        \n        # Final classification\n        x = self.relu(self.fc1(combined_features))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x\n\n# 12. Initialize model\nmodel = HybridCodeClassifier(\n    char_vocab_size=len(vocab),\n    word_vocab_size=len(word_vocab)\n).to(device)\n\n# 13. Loss and Optimizer\n# Use weighted loss to handle class imbalance\npos_weight = torch.tensor(5.0).to(device)  # Adjust weight based on class distribution\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\n# Different learning rates for different components\nparams = [\n    {'params': model.char_embedding.parameters(), 'lr': 1e-3},\n    {'params': model.lstm.parameters(), 'lr': 1e-3},\n    {'params': model.word_embedding.parameters(), 'lr': 1e-3},\n    {'params': model.pos_encoder.parameters(), 'lr': 1e-3},\n    {'params': model.transformer_layers.parameters(), 'lr': 5e-4},\n    {'params': model.fc1.parameters(), 'lr': 1e-3},\n    {'params': model.fc2.parameters(), 'lr': 1e-3}\n]\noptimizer = torch.optim.AdamW(params, lr=1e-3, weight_decay=0.01)\n\n# Learning rate scheduler\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n\n# 14. Training Function\ndef train(model, loader, optimizer, criterion, scheduler):\n    model.train()\n    running_loss = 0.0\n    \n    for batch in tqdm(loader):\n        char_encoded = batch['char_encoded'].to(device)\n        word_encoded = batch['word_encoded'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(char_encoded, word_encoded, attention_mask).squeeze(1)\n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        running_loss += loss.item()\n    \n    scheduler.step()\n    return running_loss / len(loader)\n\n# 15. Evaluation Function\ndef evaluate(model, loader):\n    model.eval()\n    preds = []\n    true = []\n    \n    with torch.no_grad():\n        for batch in loader:\n            char_encoded = batch['char_encoded'].to(device)\n            word_encoded = batch['word_encoded'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(char_encoded, word_encoded, attention_mask).squeeze(1)\n            preds.extend(torch.sigmoid(outputs).cpu().numpy())\n            true.extend(labels.cpu().numpy())\n    \n    preds = np.array(preds) >= 0.5\n    true = np.array(true)\n    \n    accuracy = accuracy_score(true, preds)\n    report = classification_report(true, preds, digits=4)\n    cm = confusion_matrix(true, preds)\n    \n    return accuracy, report, cm\n\n# 16. Training Loop\nepochs = 10\nbest_val_acc = 0\npatience = 3\ncounter = 0\nbest_model_state = None\n\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch+1}/{epochs}\")\n    \n    # Training\n    train_loss = train(model, train_loader, optimizer, criterion, scheduler)\n    print(f\"Train Loss: {train_loss:.4f}\")\n    \n    # Validation\n    val_acc, val_report, val_cm = evaluate(model, val_loader)\n    print(f\"Validation Accuracy: {val_acc:.4f}\")\n    print(val_report)\n    print(f\"Validation Confusion Matrix:\\n{val_cm}\")\n    \n    # Save best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        counter = 0\n        best_model_state = model.state_dict().copy()\n        print(f\"Model saved with validation accuracy: {val_acc:.4f}\")\n    else:\n        counter += 1\n        if counter >= patience:\n            print(f\"Early stopping triggered after {epoch+1} epochs\")\n            break\n\n# 17. Load best model and evaluate on test set\nif best_model_state:\n    model.load_state_dict(best_model_state)\n    print(\"Successfully loaded the best model\")\n\ntest_acc, test_report, test_cm = evaluate(model, test_loader)\nprint(f\"Test Accuracy: {test_acc:.4f}\")\nprint(test_report)\nprint(f\"Test Confusion Matrix:\\n{test_cm}\")\n\n# 18. Ensemble predictions with confidence threshold tuning\ndef predict_with_confidence(model, loader, threshold=0.5):\n    model.eval()\n    predictions = []\n    confidences = []\n    true_labels = []\n    \n    with torch.no_grad():\n        for batch in loader:\n            char_encoded = batch['char_encoded'].to(device)\n            word_encoded = batch['word_encoded'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(char_encoded, word_encoded, attention_mask).squeeze(1)\n            probs = torch.sigmoid(outputs).cpu().numpy()\n            \n            predictions.extend(probs >= threshold)\n            confidences.extend(probs)\n            true_labels.extend(labels.cpu().numpy())\n    \n    return np.array(predictions), np.array(confidences), np.array(true_labels)\n\n# Find optimal threshold\nthresholds = np.arange(0.3, 0.7, 0.05)\nbest_threshold = 0.5\nbest_acc = 0\n\nfor threshold in thresholds:\n    preds, _, true = predict_with_confidence(model, val_loader, threshold)\n    acc = accuracy_score(true, preds)\n    if acc > best_acc:\n        best_acc = acc\n        best_threshold = threshold\n        \nprint(f\"Optimal threshold: {best_threshold:.2f} with validation accuracy: {best_acc:.4f}\")\n\n# Final evaluation with optimal threshold\nfinal_preds, confidences, true_labels = predict_with_confidence(model, test_loader, best_threshold)\nfinal_acc = accuracy_score(true_labels, final_preds)\nfinal_report = classification_report(true_labels, final_preds, digits=4)\nfinal_cm = confusion_matrix(true_labels, final_preds)\n\nprint(f\"Final Test Accuracy: {final_acc:.4f}\")\nprint(final_report)\nprint(f\"Final Confusion Matrix:\\n{final_cm}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:44:02.271711Z","iopub.execute_input":"2025-04-29T13:44:02.272659Z","iopub.status.idle":"2025-04-29T13:49:30.939585Z","shell.execute_reply.started":"2025-04-29T13:44:02.272630Z","shell.execute_reply":"2025-04-29T13:49:30.938853Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nWord vocabulary size: 10000\nEpoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b54c7b7cff1467a8740c3a2b3bc59de"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 1.0935\nValidation Accuracy: 0.7248\n              precision    recall  f1-score   support\n\n         0.0     0.9178    0.4945    0.6427       542\n         1.0     0.6536    0.9556    0.7763       541\n\n    accuracy                         0.7248      1083\n   macro avg     0.7857    0.7251    0.7095      1083\nweighted avg     0.7858    0.7248    0.7094      1083\n\nValidation Confusion Matrix:\n[[268 274]\n [ 24 517]]\nModel saved with validation accuracy: 0.7248\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15f536d0bfe34fe1a604c30092ca0bfb"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.7996\nValidation Accuracy: 0.8680\n              precision    recall  f1-score   support\n\n         0.0     0.8771    0.8561    0.8665       542\n         1.0     0.8592    0.8799    0.8694       541\n\n    accuracy                         0.8680      1083\n   macro avg     0.8682    0.8680    0.8679      1083\nweighted avg     0.8682    0.8680    0.8679      1083\n\nValidation Confusion Matrix:\n[[464  78]\n [ 65 476]]\nModel saved with validation accuracy: 0.8680\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2300335e30274c28b4b3c497600715c9"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.6060\nValidation Accuracy: 0.8190\n              precision    recall  f1-score   support\n\n         0.0     0.9529    0.6716    0.7879       542\n         1.0     0.7461    0.9667    0.8422       541\n\n    accuracy                         0.8190      1083\n   macro avg     0.8495    0.8192    0.8150      1083\nweighted avg     0.8496    0.8190    0.8150      1083\n\nValidation Confusion Matrix:\n[[364 178]\n [ 18 523]]\nEpoch 4/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f518b5a11cb40dcbd272a2521bc3939"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.5149\nValidation Accuracy: 0.8984\n              precision    recall  f1-score   support\n\n         0.0     0.8956    0.9022    0.8989       542\n         1.0     0.9013    0.8946    0.8980       541\n\n    accuracy                         0.8984      1083\n   macro avg     0.8985    0.8984    0.8984      1083\nweighted avg     0.8985    0.8984    0.8984      1083\n\nValidation Confusion Matrix:\n[[489  53]\n [ 57 484]]\nModel saved with validation accuracy: 0.8984\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab57f1d4def4518b45735eda9d63cfa"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.4071\nValidation Accuracy: 0.8957\n              precision    recall  f1-score   support\n\n         0.0     0.9459    0.8395    0.8895       542\n         1.0     0.8555    0.9519    0.9011       541\n\n    accuracy                         0.8957      1083\n   macro avg     0.9007    0.8957    0.8953      1083\nweighted avg     0.9008    0.8957    0.8953      1083\n\nValidation Confusion Matrix:\n[[455  87]\n [ 26 515]]\nEpoch 6/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77387a99895d42ab8e53c6c6850e9590"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.3466\nValidation Accuracy: 0.9077\n              precision    recall  f1-score   support\n\n         0.0     0.9492    0.8616    0.9033       542\n         1.0     0.8731    0.9538    0.9117       541\n\n    accuracy                         0.9077      1083\n   macro avg     0.9111    0.9077    0.9075      1083\nweighted avg     0.9112    0.9077    0.9075      1083\n\nValidation Confusion Matrix:\n[[467  75]\n [ 25 516]]\nModel saved with validation accuracy: 0.9077\nEpoch 7/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbe6536ec0fb4205aa7aabc00bfb2996"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.2637\nValidation Accuracy: 0.8975\n              precision    recall  f1-score   support\n\n         0.0     0.9615    0.8284    0.8900       542\n         1.0     0.8490    0.9667    0.9041       541\n\n    accuracy                         0.8975      1083\n   macro avg     0.9052    0.8976    0.8970      1083\nweighted avg     0.9053    0.8975    0.8970      1083\n\nValidation Confusion Matrix:\n[[449  93]\n [ 18 523]]\nEpoch 8/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08d7176436cf45dda8f48dca68999999"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.1801\nValidation Accuracy: 0.9086\n              precision    recall  f1-score   support\n\n         0.0     0.9511    0.8616    0.9042       542\n         1.0     0.8733    0.9556    0.9126       541\n\n    accuracy                         0.9086      1083\n   macro avg     0.9122    0.9086    0.9084      1083\nweighted avg     0.9123    0.9086    0.9084      1083\n\nValidation Confusion Matrix:\n[[467  75]\n [ 24 517]]\nModel saved with validation accuracy: 0.9086\nEpoch 9/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb97f52c21a248c081510b5b68cf8991"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.1411\nValidation Accuracy: 0.9151\n              precision    recall  f1-score   support\n\n         0.0     0.9377    0.8893    0.9129       542\n         1.0     0.8946    0.9409    0.9171       541\n\n    accuracy                         0.9151      1083\n   macro avg     0.9161    0.9151    0.9150      1083\nweighted avg     0.9162    0.9151    0.9150      1083\n\nValidation Confusion Matrix:\n[[482  60]\n [ 32 509]]\nModel saved with validation accuracy: 0.9151\nEpoch 10/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/609 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8c3a898762b479385ffb01d7458df35"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.1144\nValidation Accuracy: 0.9178\n              precision    recall  f1-score   support\n\n         0.0     0.9381    0.8948    0.9160       542\n         1.0     0.8993    0.9409    0.9196       541\n\n    accuracy                         0.9178      1083\n   macro avg     0.9187    0.9178    0.9178      1083\nweighted avg     0.9187    0.9178    0.9178      1083\n\nValidation Confusion Matrix:\n[[485  57]\n [ 32 509]]\nModel saved with validation accuracy: 0.9178\nSuccessfully loaded the best model\nTest Accuracy: 0.9087\n              precision    recall  f1-score   support\n\n         0.0     0.9183    0.8973    0.9077      1353\n         1.0     0.8996    0.9202    0.9098      1353\n\n    accuracy                         0.9087      2706\n   macro avg     0.9089    0.9087    0.9087      2706\nweighted avg     0.9089    0.9087    0.9087      2706\n\nTest Confusion Matrix:\n[[1214  139]\n [ 108 1245]]\nOptimal threshold: 0.65 with validation accuracy: 0.9215\nFinal Test Accuracy: 0.9087\n              precision    recall  f1-score   support\n\n         0.0     0.9139    0.9024    0.9081      1353\n         1.0     0.9036    0.9150    0.9093      1353\n\n    accuracy                         0.9087      2706\n   macro avg     0.9088    0.9087    0.9087      2706\nweighted avg     0.9088    0.9087    0.9087      2706\n\nFinal Confusion Matrix:\n[[1221  132]\n [ 115 1238]]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}